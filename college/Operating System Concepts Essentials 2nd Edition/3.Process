3.1.Process Concept
3.1.1.The Process
Informally, as mentioned earlier, a process is a program in execution.
3.1.2.Process State
• New. The process is being created.
• Running. Instructions are being executed.
• Waiting. The process is waiting for some event to occur (such as an I/O
completion or reception of a signal).
• Ready. The process is waiting to be assigned to a processor.
• Terminated. The process has finished execution.
3.1.3.Process Control Block
It contains many pieces of information associated with a specific process, including these:
• Process state. The state may be new, ready, running, waiting, halted, and
so on.
• Program counter. The counter indicates the address of the next instruction
to be executed for this process.
• CPU registers. The registers vary in number and type, depending on
the computer architecture. They include accumulators, index registers,
stack pointers, and general-purpose registers, plus any condition-code
information. Along with the program counter, this state information must
be saved when an interrupt occurs, to allow the process to be continued
correctly afterward (Figure 3.4).
• CPU -scheduling information. This information includes a process priority,
pointers to scheduling queues, and any other scheduling parameters.
(Chapter 6 describes process scheduling.)
• Memory-management information. This information may include such
items as the value of the base and limit registers and the page tables, or the
segment tables, depending on the memory system used by the operating
system (Chapter 7).
• Accounting information. This information includes the amount of CPU
and real time used, time limits, account numbers, job or process numbers,
and so on.
• I/O status information. This information includes the list of I/O devices
allocated to the process, a list of open files, and so on.


3.1.4.Threads
Most modern operating systems
have extended the process concept to allow a process to have multiple threads
of execution and thus to perform more than one task at a time. This feature
is especially beneficial on multicore systems, where multiple threads can run
in parallel.

he process control block in the Linux operating system is represented by
the C structure task struct , which is found in the <linux/sched.h>
include file in the kernel source-code directory. This structure contains all the
necessary information for representing a process, including the state of the
process, scheduling and memory-management information, list of open files,
and pointers to the process’s parent and a list of its children and siblings. (A
process’s parent is the process that created it; its children are any processes
that it creates. Its siblings are children with the same parent process.) Some
of these fields include:
long state; /* state of the process */
struct sched entity se; /* scheduling information */
struct task struct *parent; /* this process’s parent */
struct list head children; /* this process’s children */
struct files struct *files; /* list of open files */
struct mm struct *mm; /* address space of this process */


3.2.Process Scheduling
The objective of multiprogramming is to have some process running at all
times, to maximize CPU utilization
3.2.1.Scheduling Queues
Job Queue
Ready Queue
device queue :the list of processes waiting for a particular I/O device

If Process is in ready queue then:-
• The process could issue an I/O request and then be placed in an I/O queue.
• The process could create a new child process and wait for the child’s termination.
• The process could be removed forcibly from the CPU , as a result of an
interrupt, and be put back in the ready queue.


3.2.2.Schedulers
A process migrates among the various scheduling queues throughout its
lifetime. The operating system must select, for scheduling purposes, processes
from these queues in some fashion. The selection process is carried out by the
appropriate scheduler.
-long-term scheduler : controles degree of multiprogramming
-short-term scheduler
-medium-term scheduler
3.2.3.Context Switch

3.3.Operations on Processes
3.3.1.Process Creation
When a process creates a new process, two possibilities for execution exist:
1. The parent continues to execute concurrently with its children.
2. The parent waits until some or all of its children have terminated.
here are also two address-space possibilities for the new process:
1. The child process is a duplicate of the parent process (it has the same
program and data as the parent).
2. The child process has a new program loaded into it.
#see program.
3.3.2.Process Termination
A parent may terminate the execution of one of its children for a variety of
reasons, such as these:
• The child has exceeded its usage of some of the resources that it has been
allocated. (To determine whether this has occurred, the parent must have
a mechanism to inspect the state of its children.)
• The task assigned to the child is no longer required.
• The parent is exiting, and the operating system does not allow a child to
continue if its parent terminates.

Some systems do not allow a child to exist if its parent has terminated. In
such systems, if a process terminates (either normally or abnormally), then
all its children must also be terminated. This phenomenon, referred to as
cascading termination, is normally initiated by the operating system.

A process that has terminated, but whose parent has not yet called wait() , is
known as a zombie process.

Now consider what would happen if a parent did not invoke wait() and
instead terminated, thereby leaving its child processes as orphans. Linux and
UNIX address this scenario by assigning the init process as the new parent to
orphan processes. (Recall from Figure 3.8 that the init process is the root of the
process hierarchy in UNIX and Linux systems.) The init process periodically
invokes wait() , thereby allowing the exit status of any orphaned process to be
collected and releasing the orphan’s process identifier and process-table entry.

3.4.Interprocess Communication [shared memory and message passing.]
There are several reasons for providing an environment that allows process
cooperation:
• Information sharing. Since several users may be interested in the same
piece of information (for instance, a shared file), we must provide an
environment to allow concurrent access to such information.
• Computation speedup. If we want a particular task to run faster, we must
break it into subtasks, each of which will be executing in parallel with the
others. Notice that such a speedup can be achieved only if the computer
has multiple processing cores.
• Modularity. We may want to construct the system in a modular fashion,
dividing the system functions into separate processes or threads, as we
discussed in Chapter 2.
• Convenience. Even an individual user may work on many tasks at the
same time. For instance, a user may be editing, listening to music, and
compiling in parallel.

from page123
